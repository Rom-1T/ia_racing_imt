{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<img src= \"https://datascientest.fr/train/assets/logo_datascientest.png\" style=\"height:150px\"> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h1 style = \"text-align:center\" > Image processing </h1> \n",
    "<h2 style = \"text-align:center\"> Comment effectuer des transformations avancées sur une image </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "### Contexte et objectif\n",
    "\n",
    "> Nous avons déjà vu dans les notebooks précédents comment lire, modifier et filtrer facilement une image avec la librairie **`cv2`** (OpenCV). Nous pouvons aller encore plus loin en explorant des méthodes d'analyse d'image plus avancées permettant notamment d'améliorer potentiellement les performances d'un algorithme de classification.\n",
    ">\n",
    "> L'objectif de ce notebook est de découvrir des algorithmes de détection de formes et des méthodes de transformation morphologique comme l'érosion et la dilatation.\n",
    ">\n",
    "> Commençons par la phase d'importation des packages.\n",
    "\n",
    "* Importer les packages **`numpy`**, **`cv2`** et **`pyplot`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Dans le notebook précédent nous avons vu qu'il était possible de supprimer du bruit dans une image comme les bruits poivre et sel ou gaussien, et également par des techniques de seuil changer la perspective de l'image. \n",
    ">\n",
    "> Nous pouvons aller plus loin, pour ne pas simplement corriger des bruits éventuels, mais aussi détecter des formes dans l'image. Nous allons utiliser les fonctions **`GaussianBlur`** et **`Canny`** de **`cv2`**. Il est important dans un premier temps d'éliminer le bruit gaussien qui peut être présent pour obtenir ensuite une meilleure détection de formes. \n",
    ">\n",
    "> Comme nous l'avons vu la fonction **`GaussianBlur`** fonctionne comme un filtre classique avec l'utilisation d'un noyau de convolution de dimension renseignée au préalable.\n",
    ">\n",
    "> La fonction **`Canny`** de **`cv2`** est l'implémentation de l'algorithme de John Canny développé en 1986. Il a été conçu pour détecter dans une image les contours caractéristiques. Pour chaque pixel ce dernier calcule l'intensité du contour selon une méthode spécifique. Ensuite pour chaque pixel l'algorithme décide si oui ou non l'intensité est suffisament forte pour considérer le pixel comme un contour important. Cette décision est prise à l'aide de deux seuils préalablement définis : \n",
    "* Si l'intensité est inférieure au seuil minimal, le pixel est rejeté\n",
    "* Si l'intensité est supérieure au seuil maximal, le pixel est accepté comme contour\n",
    "* Si l'intensité est entre les deux seuils, le pixel est accepté comme contour s'il est connecté à un pixel déjà accepté\n",
    ">\n",
    "> Cette procédure de sélection est ce qu'on appelle un seuillage à hystérésis. Vous trouverez des précisions sur l'algorithme **`Canny`** [ici]('https://fr.wikipedia.org/wiki/Filtre_de_Canny').\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple : utilisation de **GaussianBlur** et **Canny** </span><br>\n",
    "```python \n",
    "    filtre = cv2.GaussianBlur(mon_image,(3,3),0) #pour supprimer le bruit gaussien dans mon_image\n",
    "    edges = cv2.Canny(filtre,100,200) #pour détecter les formes de mon_image```\n",
    "\n",
    "\n",
    "* Dans un premier temps, lire en couleur, l'image *building* qui est au format *.jpg*, la stocker dans une variable nommée **`building_color`**\n",
    "* En utilisant la fonction **`GaussianBlur`** de **`cv2`**, éliminer le bruit gaussien dans **`building`**\n",
    "* En utilisant la fonction **`Canny`** de **`cv2`**, détecter les formes de **`building`** en fixant les arguments **minVal** et **maxVal** respectivement à 100 et 200\n",
    "* Afficher l'image filtrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Une fois l'image filtrée à l'aide de l'algorithme de **`Canny`**, on peut utiliser la fonction **`HoughLinesP`** pour déterminer les coordonnées des lignes pertinentes de l'image. Cette fonction renvoie un array  Si vous souhaitez avoir plus de détails sur la théorie mathématique derrière cette fonction, vous trouverez des informations [ici](https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/hough_lines/hough_lines.html). \n",
    "> \n",
    "> Différents arguments sont utilisés dans la fonction : \n",
    "> * **dst**: Sortie du détecteur de formes. Il devrait s'agir d'une image en niveaux de gris (bien qu'il s'agisse en fait d'une image binaire)\n",
    "> * **lignes** : Un vecteur qui va stocker les paramètres (x_{début}, y_{début}, x_{fin}, y_{fin}) des lignes détectées\n",
    "> * **rho** : La résolution du paramètre r en pixels.\n",
    "> * **theta** : La résolution du paramètre \\theta en radians.\n",
    "> * **threshold**: Le nombre minimum d'intersections pour \"détecter\" une ligne\n",
    "> * **minLinLength**: Le nombre minimum de points qui peuvent former une ligne. Les lignes ayant moins que ce nombre de points ne sont pas prises en compte.\n",
    "> * **maxLineGap**: L'écart maximum entre deux points à considérer dans une même ligne.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple : utilisation de **HoughLinesP**</span><br>\n",
    "```python \n",
    "   lines = cv2.HoughLinesP(edges,rho=3,theta=np.pi / 20,threshold=100,minLineLength=0,maxLineGap= 20)```\n",
    "   \n",
    "* Appliquer la fonction **`HoughLinesP`** à **`edges`** et stocker le résultat dans une variable **`lines`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Une fois que nous avons stocker les lignes pertinentes nous allons les afficher en rouge dans l'image. Pour cela nous avons besoin dans un premier temps de créer un tableau rempli de 0 de même dimension que l'image **`building_color`** que nous appellerons **`line_img`**. \n",
    ">\n",
    "> La fonction **`line`** de **`cv2`** permet de tracer les lignes dans l'image **`line_img`**. Il suffit de se  reservir des coordonnées stockées dans la variable **`lines`**. Elle contient pour chaque ligne les coordonnées du point de départ et du point de fin. L'argument **color** permet de donner une couleur spécifique aux lignes que nous souhaitons mettre en valeur dans l'image. L'argument **thickness** permet de gérer l'épaisseur des lignes.\n",
    "> \n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple : utilisation de **lines**</span><br>\n",
    "```python \n",
    "   for line in lines:\n",
    "    for x1, y1, x2, y2 in line:\n",
    "        cv2.line(mon_image, (x1, y1), (x2, y2), color = [255, 0, 0], thickness=3)```\n",
    ">\n",
    "> Une fois que nous avons que nous avons défini les lignes dans l'image **`line_img`** il suffit de 'concaténer' les deux images **`line_img`** et **`building_color`** pour faire apparaître ces lignes dans l'image d'origine. Pour cela nous allons utiliser la fonction **`addWeighted`**. Elle permet de calculer la somme pondérée de deux images.\n",
    ">\n",
    "> Pour utiliser la fonction il faut mettre dans l'ordre la première image, le poids associé, la seconde image, le poids associé et enfin un scalaire à ajouter en plus qu'on mettre à 0.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple : utilisation de **addWeighted**</span><br>\n",
    "```python \n",
    "  cv2.addWeighted(mon_image_1, 0.8, mon_image_2, 1.0, 0.0)```\n",
    "\n",
    "* Créer **`line_img`** un tableau composé de zeros avec les mêmes dimensions que **`building_color`**.\n",
    "* En utilisant la fonction **line**, déterminer en rouge les lignes détectées précedemment dans **`line_img`**.\n",
    "* En utilisant la fonction **`addWeighted`**, sommer les images **`line_img`** et **`building_color`** et stocker le résultat dans une variable nommée **`building_lines`**.\n",
    "* Afficher le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> On peut également utiliser des filtres avancés pour détecter des formes dans l'image. Le filtre de Sobel permet notamment de détecter les bords verticaux ou horizontaux d'une image. Comme pour un filtre classique le filtre Sobel utilise un noyau de convolution particulier qui lui permet de détecter les formes horizontales ou verticales dans l'image. \n",
    ">\n",
    "> OpenCV met à disposition une fonction **`Sobel`** qui permet d'appliquer facilement le filtre à une image. Les arguments **dx** et **dy** permettent de déterminer si on souhaite mettre en évidence les bords verticaux ou horizontaux de l'image. Par exemple la combinaison (dx, dy) = (1,0) mettra en évidence les bords verticaux de l'image. L'inverse vous donnera les bords horizontaux. L'argument **ddepth** doit être égal à **cv2.CV_64F** pour une question technique liée aux types d'entiers utilisés.\n",
    ">\n",
    "> Suivant les combinaisons **dx**, **dy** ((1,0) ou (0,1)) le noyau de convolution utilisé n'est pas le même. Voici les deux noyaux utilisés suivant les cas :\n",
    ">\n",
    "><img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/sobel_filters.png\" style=\"height:300px\">\n",
    ">\n",
    "> Le noyau de gauche est utilisé pour mettre en évidence les bords verticaux de l'image tandis que celui de droite est utilisé pour mettre en évidence les bords horizontaux. \n",
    ">\n",
    "> Le filtre s'utilise sur des images en **niveaux de gris**.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple : utilisation de **Sobel** </span><br>\n",
    "```python \n",
    "    sobel = cv2.Sobel(mon_image, ddepth = cv2.CV_64F, dx = 1, dy = 0) #pour détecter les bords verticaux dans mon_image```\n",
    "\n",
    "* Dans un premier temps, lire en niveaux de gris, l'image building qui est au format .jpg, la stocker dans une variable nommée **`street_gray`**\n",
    "* En utilisant **`Sobel`**, filtrer **`street_gray`** de sorte à faire apparaître les bords verticaux à l'intérieur de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> On constate que le filtre a bien détecté les bords verticaux dans l'image. Ce type de filtre est utile pour mieux comprendre les structures présentes dans une image comme une maison par exemple. \n",
    ">\n",
    "> On peut aller un peu plus loin avec des filtres plus avancés comme le **`Laplacian`**. Il utilise la mise en évidence des discontinuités de niveaux de gris dans une image et tente de désaccentuer les régions dont les niveaux de gris varient lentement. Le résultat de cette opération est la production d'images dont les bords sont grisâtres et qui présentent d'autres discontinuités sur un fond sombre. Cela produit des bords intérieurs et extérieurs dans une image.\n",
    ">\n",
    "> Une différence entre le **`Laplacian`** et les autres filtres comme **`Sobel`** est que, contrairement aux autres opérateurs, le laplacien ne prend pas de bords dans une direction particulière comme vertical ou horizontal. \n",
    ">\n",
    ">  L'argument **ddepth** doit être égal à **cv2.CV_64F** pour une question technique liée aux types d'entiers utilisés.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple : utilisation de **Laplacian** </span><br>\n",
    "```python \n",
    "    laplacian = cv2.Laplacian(mon_image, ddepth = cv2.CV_64F)```\n",
    "    \n",
    "* En utilisant la fonction **`Laplacian`**, filtrer **`street_gray`** et observer le résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Le filtrage paraît plus affiné qu'avec **Sobel** et permet de distinguer des structures plus complexes au sein de l'image. \n",
    ">\n",
    "> Ces filtres sont déterminants dans la lecture d'images pour déterminer des caractéristiques clés. Des algorithmes complexes comme les réseaux de neurones CNN utilisent un très grand nombre de filtres pour extraire au fur et à mesure des informations clés de plus en plus complexes leur permettant d'apprendre de manière efficace et par la suite faire de puissantes prédictions.\n",
    ">\n",
    "> On peut également utiliser ce qu'on appelle des méthodes de transformations morphologiques pour détecter des structures pertinentes et éliminer celles non pertinentes pour la compréhension de l'image. Les deux méthodes de base très utilisées sont la dilatation et l'érosion. \n",
    ">\n",
    "> Une première transformation morphologique simple à appliquer est l'érosion. Elle est utilisée pour faire disparaître les limites des objets de premier plan et également pour éliminer les petits bruits blancs des images. L'érosion peut également être utilisée pour détacher deux images reliées entre elles. \n",
    ">\n",
    "> Elle s'utilise facilement avec la fonction **`erode`** de **`cv2`**. Il est nécessaire avant de définir un noyau de convolution qui peut avoir n'importe quelle forme ou taille. On définit le point d'ancrage du noyau comme le centre du noyau.\n",
    ">\n",
    "> Lorsque le noyau balaie l'image, nous calculons la valeur minimale de la fenêtre recouverte par le noyau et nous remplaçons le point d'ancrage par cette valeur. \n",
    ">\n",
    "> L'érosion a pour conséquence d'affiner l'image et notament les zones claires. Pour comprendre et visualiser les effets de l'érosion nous allons utiliser **`erode`** sur une image d'araignée.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple : utilisation de **erode** </span><br>\n",
    "```python \n",
    "    kernel = np.ones((3,3),np.uint8) # création du noyau\n",
    "    erosion = cv2.erode(mon_image, kernel) # erosion de mon_image```\n",
    "    \n",
    "\n",
    "* Lire, en niveaux de gris, l'image *spider* au format *.jpeg* et la stocker dans une variable nommée **`spider_gray`**\n",
    "* Redimensionner l'image en taille 150x150 à l'aide de **`resize`**\n",
    "* Inverser les nuances de gris pour mettre en blanc les formes au premier plan\n",
    "* Filtrer l'image avec un filtre gaussien et la stocker dans une variable nommée **`filtre`**\n",
    "* Effectuer 3 érosions à l'aide de la fonction **`erode`** de **`cv2`** en utilisant 3 noyaux de convolutions composés uniquement de 1 mais de dimensions respectives (3,3), (5,5) et (7,7) \n",
    "* Afficher le résultat pour chaque érosion ainsi que l'image d'origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> L'érosion permet d'isoler le corps de l'araignée et d'éliminer la présence des pattes. C'est très utile pour isoler des parties spécifiques que l'on souhaite identifier et étudier. \n",
    ">\n",
    "> Une autre transformation morphologique très connue est la dilatation. Elle produit l'effet inverse de l'érosion et fonctionne de manière identique. \n",
    ">\n",
    "> Il est nécessaire avant de définir un noyau de convolution qui peut avoir n'importe quelle forme ou taille. On définit le point d'ancrage du noyau comme le centre du noyau. Lorsque le noyau balaie l'image, nous calculons la valeur maximale de la fenêtre recouverte par le noyau et nous remplaçons le point d'ancrage par cette valeur.\n",
    ">\n",
    "> La dilatation est facilement utilisable avec la fonction **`dilate`** de **`cv2`**. \n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Exemple : utilisation de **dilate** </span><br>\n",
    "```python \n",
    "    kernel = np.ones((3,3),np.uint8) # création du noyau\n",
    "    dilatation = cv2.dilate(mon_image, kernel) # erosion de mon_image```\n",
    "    \n",
    "* Effectuer une dilatation de l'image **`erosion_2`** à l'aide d'un noyau de convolution composé de 1 de taille (5,5)\n",
    "* Afficher l'image dilatée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Effectuer la différence entre l'image d'origine **`spider_gray`** et l'image dilatée **`dilation`**\n",
    "* Afficher le résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> On peut voir qu'en dilatant le corps de l'araignée et en soustrayant à l'image d'origine, on obtient les contours de l'araignée. Ces techniques de transformations morphologiques permettent de détecter ou d'isoler des structures pertinentes au sein d'une image.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    ">Dans ce notebook vous aurez appris à :\n",
    ">\n",
    ">* Détecter des formes complexes en utilisant des algorithmes avancés comme **`Canny`**.\n",
    ">* Effectuer des filtrages avancés comme **`Sobel`** ou **`Laplacian`** pour détecter des formes verticales ou horizontales dans une image. \n",
    ">* Effectuer des transformations morphologiques simples pour éroder ou dilater une image."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Default Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
