{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet de cet exercice consiste à créer un modèle de reconnaissance d'image capable de prédire s'il y a un père noël sur l'image. Le modèle devra être le plus précis en suivant une méthode qui minimise la taille des données pour un maximum de précision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Générateur d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'utiliser les images d'une base de données, il faut souvent traiter en amont les images. En deep learning, le réseau de neurones doit s'entraîner sur des lots d'images de la base de données. La classe ImageDataGenerator permet de générer des lots d'images transformées pour entraîner votre réseau. Dans ce test vous devrez vous appuyer sur la documentation cliquez ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import ImageDataGenerator du sous-module keras.preprocessing.image\n",
    "- Créer train_datagen une instance de ImageDataGenerator avec pour paramètres :\n",
    "    rescale = 1./255, <br>\n",
    "    shear_range = 0.2, <br>\n",
    "    zoom_range = 0.2, <br>\n",
    "    rotation_range = 40, <br>\n",
    "    width_shift_range = 0.2, <br>\n",
    "    height_shift_range = 0.2, <br>\n",
    "    horizontal_flip = True, <br>\n",
    "    fill_mode = 'nearest' <br>\n",
    "- Créer test_datagen, une instance de ImageDataGenerator avec comme unique paramètre rescale = 1./255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de données et importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux dossiers s'intitulant images et images_test contiennent chacun deux sous-dossiers d'images. santa qui ne contient que des images de père Noël, et not_santa  qui ne contient que des images aléatoires d'objets et de personnes qui ne sont pas des pères Noël. <br>\n",
    "Pour importer et transformer les images avec la classe ImageDataGenerator, on utilise la méthode flow_from_directory qui prend en argument le chemin donnant accès aux dossiers. Elle détecte automatiquement les images et les classes dans deux catégories différentes car les images sont dans deux dossier différents. <br>\n",
    "Pour plus d'information sur flow_from_directory, cliquez ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pour importer vos images, lancer le code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lancer le code suivant\n",
    "\n",
    "#On prend des lots de 32\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('images',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('images_test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage de la donnée \"Augmentée\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons le réultat d'une augmentation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exécuter la cellule suivante pour observer des données augmentées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batches_real = test_datagen.flow_from_directory('images', target_size = (512, 512), batch_size = 16, class_mode = 'categorical')\n",
    "batches_augmented = train_datagen.flow_from_directory('images', target_size = (512, 512), batch_size = 16, class_mode = 'catgorical')\n",
    "\n",
    "x_batch_augmented, y_batch_augmented = next(batches_augmented)\n",
    "x_batch_real, y_batch_real = next(batches_real)\n",
    "\n",
    "for i in range(16):\n",
    "    image_augmented = x_batch_augmented[i]\n",
    "    image_real = x_batch_real[i]\n",
    "    \n",
    "    title_add_on = 'random image'\n",
    "    if y_batch_augmented[i][1]: title_add_on = \"santa\"\n",
    "        \n",
    "        plt.subplot(221)\n",
    "        plt.imshow(image_real)\n",
    "        plt.title(\"original\" + title_add_on)\n",
    "        \n",
    "        plt.subplot(222)\n",
    "        plt.imshow(image_augmented)\n",
    "        plt.title(\"augmented\" + title_add_on)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quelles sont les transformations apportées sur la data augmentée ? <br>\n",
    "- Selon vous, en quoi l'augmentation de données est-elle utile pour l'entrainement d'un réseau de neurones ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Les transformations apportées par la data augmentée sont des combinaisons des transformations suivantes :\n",
    "- shear_range = 0.2 : cisaillement de l'image,\n",
    "- zoom_range = 0.2 : un zoom allant jusqu'à 20% de l'image,\n",
    "- rotation_range = 40 : des rotations pouvant aller jusqu'à 40°,\n",
    "- width_shift_range = 0.2 : translation de l'image en horizontal pouvant aller de + ou - 20% de la largeur de l'image,\n",
    "- height_shift_range = 0.2 : translation de l'image en vertical pouvant aller de + ou - 20% de la hauteur de l'image,\n",
    "- horizontal_flip = True : retournement de l'image horizontalement,\n",
    "- fill_mode = 'nearest' : les pixels en dehors de l'image originale sont remplis de la manière aaaaaaaaa|abcd|dddddddd\n",
    "\n",
    "\n",
    "\n",
    "Si on entraine un réseau de neurones sur trop peu d'images, le modèle pourrait avoir tendance à faire de l'overfitting\n",
    "(sur-apprendre à partir de l'échantillon d'entrainement sans être capable d'effectuer des prédictions pertinentes\n",
    "sur de nouvelles images). Pour résoudre ce problème, une solution est d'augmenter la taille du dataset. Seulement,\n",
    "labelliser tout un set d'images peut être très chronophage. L'augmentation de données permet d'éviter ce problème et\n",
    "de générer de nouvelles images labellisées à partir de celles déjà disponibles. \n",
    "L'augmentation de données permettra donc d'éviter l'overfitting notamment.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour classer ces images, vous pouvez vous appuyer sur le réseau de neurones suivant : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie de la méthode .summary() de votre modèle devra ressembler à ceci :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implémenter votre modèle dans une instance nommée classifier.\n",
    "- Entrainer votre modèle jusqu'à atteindre une précision de validation val_accuracy supérieure à 0.85 en choisissant judicieusement les paramètres d'entrainement. <br>\n",
    "\n",
    "NB : training_set est un générateur, il faut utiliser la méthode fit_generator là où vous avez l'habitude d'utiliser la méthode fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "conv2d_5 = conv2D(filters = 30,\n",
    "                  kernel_size = (5, 5),\n",
    "                  padding = 'valid',\n",
    "                  input_shape = (64, 64, 3),\n",
    "                  activation = 'relu')\n",
    "max_pooling2d_5 = MaxPooling2D(pool_size = (2, 2))\n",
    "conv2d_6 = Conv2D(filters = 16,\n",
    "                   kernel_size = (3, 3),\n",
    "                   padding = 'valid',\n",
    "                   activation = 'relu')\n",
    "max_pooling2d_6 = MaxPooling2D(pool_size = (2, 2))\n",
    "flatten_3 = Flatten()\n",
    "dense_5 = Dense(units = 128,\n",
    "                activation = 'relu')\n",
    "dense_6 = Dense(units = 10,\n",
    "                activation = 'softmax')\n",
    "\n",
    "classifier.add(conv2d_5)\n",
    "classifier.add(max_pooling2d_5)\n",
    "classifier.add(conv2d_6)\n",
    "classifier.add(max_pooling2d_6)\n",
    "classifier.add(flatten_3)\n",
    "classifier.add(dense_5)\n",
    "classifier.add(dense_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Adamax, SGD\n",
    "\n",
    "classifier.compile(optimizer = Adam(learning_rate = 1e-3), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "#categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = training_set.n #nb d'images\n",
    "nb_test = test_set.n\n",
    "\n",
    "history = classifier.fit_generator(generator = training_set,\n",
    "                              epochs = 5,\n",
    "                              steps_per_epoch = nb_train//32,\n",
    "                              validation_data = test_set,\n",
    "                              validation_steps = nb_test//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model acc by epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exécuter le code suivant pour observer la probabilité que l'on obtient pour une image de Thor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "txt = 'thor.jpg' # Préciser le chemin local\n",
    "text_image = image.load_img(txt, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)/255\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "proba = round(100*classifier.predict_proba(test_image)[0][1], 2)\n",
    "if proba < 50:\n",
    "    santa_or_not = 'Santa'\n",
    "img = mpimg.imread(txt)\n",
    "plt.axis('off')\n",
    "plt.text(-10, -15, santa_or_not+': '+str(proba)+'%', color = (1, 0, 0), fontsize = 20, fontweight = 'extra bold')\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réitérer le test avec les photos suivantes :\n",
    "- chien.jpg\n",
    "- chat.jpg\n",
    "- selfie.jpg\n",
    "- santa_rock.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['chien.jpg', 'chat.jpg', 'selfie.jpg', 'santa_rock.jpg']\n",
    "j = 1\n",
    "\n",
    "for img in images:\n",
    "    text_image = image.load_img(img, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)/255\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "    proba = round(100*classifier.predict_proba(test_image)[0][1], 2)\n",
    "    if proba < 50:\n",
    "        santa_or_not = 'Santa'\n",
    "    img = mpimg.imread(img)\n",
    "    plt.subplot(2, 2, j)\n",
    "    j = j+1\n",
    "    plt.axis('off')\n",
    "    plt.text(-10, -15, santa_or_not+': '+str(proba)+'%', color = (1, 0, 0), fontsize = 20, fontweight = 'extra bold')\n",
    "    imgplot = plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
