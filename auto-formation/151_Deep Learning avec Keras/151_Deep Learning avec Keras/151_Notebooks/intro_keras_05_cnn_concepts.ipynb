{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" style=\"height:150px\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><h1> Introduction au Deep Learning avec Keras </h1></center>\n",
    "<center><h2> Types de Couches </h2></center>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "> L'objectif de ce module est de vous familiariser avec les types de couches les plus utilisés dans la construction de réseaux de neurones profonds.\n",
    ">\n",
    "\n",
    "## Rappel : Les couches *Dense*\n",
    "\n",
    "> Les couches *Dense* ou *Fully-connected* correspondent aux couches que nous trouvons dans le modèle MLP vu dans le module théorique précédent.\n",
    ">\n",
    "> Chaque neurone de cette couche possède un vecteur de poids de la même taille que le vecteur qui lui est passé en entrée et un terme de biais.\n",
    ">\n",
    "> Les opérations effectuées par cette couche sont:\n",
    "> * **Produit scalaire** entre les vecteur de poids de chaque neurone et le vecteur d'entrée **auquel on ajoute un terme de biais** spécifique à chaque neurone.\n",
    "> * **Activation** des résultats des produits scalaires grâce par une fonction d'activation **non-linéaire** telle que $ReLU$, $tanh$ ou $sigmoid$. \n",
    "> * **Concaténation des activations** pour former un nouveau vecteur qui sera passé en **entrée de la couche suivante**.\n",
    ">\n",
    "> Dans l'animation intéractive suivante, nous avons illustré pour vous chaque étape de ces opérations:\n",
    "> * La couche d'entrée contient 5 neurones, donc la taille du vecteur d'entrée et du vecteur de poids de chaque neurones de la couche dense suivante sera de 5.\n",
    "> * La première couche dense contient 3 neurones, donc la taille de son vecteur de sortie sera de 3 et la taille du vecteur de poids de chaque neurone de la couche dense suivante sera de 3.\n",
    "> * La deuxième couche dense contient 4 neurones, donc la taille de son vecteur de sortie sera de 4.\n",
    "\n",
    "* Pour interagir avec la figure, cliquez sur le bouton *Next* pour aller à l'étape suivante et *Previous* pour revenir à l'étape précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     1
    ],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b528ee46a854b7f8914e1942ef5c28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(animation_duration=1000, background_style={'fill': 'white'}, fig_margin={'top': 60, 'bottom': 60, 'left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ed7947ba5543b29b3c58f715ddb084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Previous', disabled=True, style=ButtonStyle()), Button(description='Next', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interaction_cnn import show_dense\n",
    "show_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Les couches de Convolution\n",
    "\n",
    "> Les couches de convolution sont très utilisées pour la *classification d'images*. Avant d'aborder directement les opérations effectuées par une couche de convolution, il est important de comprendre l'opération à la base du neurone de cette couche, **le produit de convolution**.\n",
    ">\n",
    "> Le produit de convolution est une opération qui ressemble beaucoup au produit scalaire, sauf qu'il ne s'effectue pas sur un vecteur mais sur une matrice:\n",
    ">\n",
    "> D'un côté nous avons une matrice d'entrée, souvent appelée **tuile** ou ***convolution patch*** en anglais, et d'un autre nous avons une matrice de convolution, souvent appelée  **noyau de convolution**, **filtre** ou ***convolution kernel*** en anglais.\n",
    ">\n",
    "> Ces deux matrices **doivent absolument avoir les mêmes dimensions** pour calculer leur produit de convolution.\n",
    ">\n",
    "> Les étapes du produit de convolution sont les mêmes que celles du produit scalaire:\n",
    "> * Produit terme à terme des deux matrices.\n",
    "> * Somme des produits.\n",
    ">\n",
    "> Dans l'animation interactive suivante, nous illustrons le produit de convolution entre une tuile et un noyau de convolution de dimensions $3$x$3$.\n",
    "\n",
    "* Pour interagir avec la figure, cliquez sur le bouton *Next* pour aller à l'étape suivante et *Reset* pour redémarrer l'animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba05e9427e74f5aa35fca755229f8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(animation_duration=1000, background_style={'fill': 'white'}, fig_margin={'top': 60, 'bottom': 60, 'left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04121f5902fc47ccace04e887909cbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Reset', style=ButtonStyle()), Button(description='Next', style=ButtonStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interaction_cnn import show_one_operation_conv\n",
    "show_one_operation_conv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Une image est une matrice de pixels. Nous pouvons lui appliquer le produit de convolution.\n",
    ">\n",
    "> Pour effectuer cette opération sur une image entière, **il faut d'abord la découper en plusieurs tuiles de mêmes dimensions que le noyau de convolution que nous voulons utiliser.** \n",
    ">\n",
    "> Ensuite, nous pouvons effectuer le produit de convolution entre chaque tuile et le noyau.\n",
    ">\n",
    "> Enfin, nous allons concaténer tous ces produits pour obtenir une nouvelle image dite *convolée* ou *filtrée*. Lorsque nous appliquons cette technique en *deep learning*, nous allons aussi utiliser une fonction d'activation non-linéaire pour les mêmes raisons que dans l'algorithme MLP.\n",
    ">\n",
    "> Dans la figure interactive suivante, nous illustrons la convolution d'une image de dimensions $4$x$4$ par un noyau de convolution de dimensions $3$x$3$:\n",
    "> * Etape 1: Découpage de l'image en plusieurs tuiles convolables. Chaque tuile a une couleur différente.\n",
    "> * Etape 2: Produits de convolutions entre chaque tuile et le noyau.\n",
    "> * Etape 3: Activation et concaténation des produits en une nouvelle matrice.\n",
    "\n",
    "* Executer la cellule suivante pour afficher l'interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450063b6d8a144908e3f328642abd256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(animation_duration=1000, background_style={'fill': 'white'}, fig_margin={'top': 60, 'bottom': 60, 'left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a61c576994c4ce5b330c064cb434956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Previous', disabled=True, style=ButtonStyle()), Button(description='Next', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interaction_cnn import show_operation_conv\n",
    "show_operation_conv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Pour quelle raison faisons-nous cette opération? Quels sont les avantages à utiliser cette technique?\n",
    ">\n",
    "> Comme vous allez le voir, la convolution d'une image est très facilement interprétable.\n",
    ">\n",
    "> Dans la figure interactive suivante, nous illustrons la convolution d'une photo du Taj-Mahal par un noyau de convolution de dimensions $3$x$3$. \n",
    ">\n",
    "> La photo est en noir et blanc pour qu'elle correspondent à une matrice de pixels simple, mais l'opération peut être réalisée sur les matrices des composantes rouges, vertes et bleues d'une photo en couleur.\n",
    "\n",
    "* Pour interagir avec cette figure, vous pouvez soit séléctionner un des noyaux de convolutions de la liste, soit modifier manuellement les coefficients du noyau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48c1179dc01404f83a32229afc9fc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Convolution Kernel', layout=Layout(margin='10px')), HBox(children=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c5461ab68144dbb37cc6138f6da3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('Identity', 'Contrast', 'Edge Detection', 'Vertical Edge Detection', 'Horizontal Edge De…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interaction_cnn import show_conv\n",
    "show_conv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> La convolution d'une image peut être vue comme une extraction de features. Par exemple, les noyaux servant à détecter les bords pourraient être utiles pour classifier certaines formes géométriques.\n",
    ">\n",
    "> L'intêret des neurones de convolution est que par l'entraînement il pourront trouver eux mêmes les **meilleurs noyaux de convolution à utiliser pour extraire des features à partir d'une image**.\n",
    "\n",
    "## Couches de Régularisation\n",
    "\n",
    "> Les réseaux de neurones contiennent **énormément** de paramètres, en particulier les couches denses. C'est pour cette raison qu'**ils sont très susceptibles au surapprentissage**, c'est-à-dire qu'ils auront une très bonne performance sur l'échantillon d'entraînement, mais cette performance ne pourra pas se généraliser sur l'échantillon de test.\n",
    ">\n",
    "> De plus, dans certains problèmes comme la classification d'images ou de sons, le nombre de variables est tellement élevé que les données se retrouvent éparpillée dans un espace de très grande dimension. Il est alors très difficile d'entraîner un modèle sur des données ayant autant de variance. Ce problème est connu comme le **fléau** ou **la malédiction de la dimensionnalité** (*Curse of Dimensionality*).\n",
    ">\n",
    "> Pour cela il existe plusieurs techniques spécifiques au *deep learning* qui permettront de réduire simultanément le nombre de variables et le nombre de paramètres du modèle tout en préservant au maximum l'essentiel des caractéristiques des données et la performance du modèle.\n",
    ">\n",
    "> Ces techniques s'appellent des **techniques de régularisation**.\n",
    ">\n",
    "> Les opérations que nous verrons dans la suite sont souvent illustrées par des \"couches\" car elles se font sur la sortie d'une couche de neurones et le résultat sera transmis à la couche de neurones suivante.\n",
    "\n",
    "## Couche de *Max-Pooling*\n",
    "\n",
    "> La couche de *Max-Pooling* s'utilise lorsque les données sur lesquelles nous travaillons sont des matrices. Le concept du *max-pooling* est très simple:\n",
    "> * La matrice est découpée en plusieurs petites tuiles contenant des valeurs de la matrice.\n",
    "> * De chaque tuile on extrait la **valeur maximale**.\n",
    "> * On recompose une matrice ne contenant que les valeurs maximales de chaque tuile.\n",
    ">\n",
    "> Nous avons illustré l'opération de ***max-pooling* avec une taille de tuile 2x2** dans la figure interactive suivante. La matrice contient des valeurs représentées par la couleur bleue. Plus la cellule de la matrice est claire, plus sa valeur est élevée.\n",
    "\n",
    "* Pour interagir avec cette figure, cliquer sur le bouton *Next* pour aller à l'étape suivante et *Previous* pour aller à l'étape précédente. Le bouton *Shuffle Colors* vous permet de changer au hasard les valeurs de la matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74660c0d78548cb833803984cfee397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(animation_duration=1000, background_style={'fill': 'white'}, fig_margin={'top': 60, 'bottom': 60, 'left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a3dd97dfd741b0b48cf40e3df85cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Previous', disabled=True, style=ButtonStyle()), Button(description='Next', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31208ddc55b47188eb6080a434598d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Shuffle Colors', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interaction_cnn import show_maxpool\n",
    "show_maxpool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Couche de *Average-Pooling*\n",
    "\n",
    "> Comme pour le *max-pooling*, l'*Average-Pooling* s'effectue sur des matrices. L'opération se déroule ainsi:\n",
    "> * La matrice est découpée en plusieurs petites tuiles contenant des valeurs de la matrice.\n",
    "> * De chaque tuile on extrait la **moyenne**.\n",
    "> * On recompose une matrice ne contenant que les moyennes de chaque tuile.\n",
    ">\n",
    "> Comme pour la couche précédente, nous illustrons l'opération de *average-pooling* avec une taille de tuile 2x2 avec la figure interactive ci-dessous. Pour mieux illustrer le concept de moyenne, nous représentons les valeurs de la matrice par des couleurs de toutes les régions du spectre.\n",
    "\n",
    "* Pour interagir avec cette figure, cliquer sur le bouton *Next* pour aller à l'étape suivante et *Previous* pour aller à l'étape précédente. Le bouton *Shuffle Colors* vous permet de changer au hasard les couleurs de la matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ad4fd58e534310b82d8d3b9d56ae48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(animation_duration=1000, background_style={'fill': 'white'}, fig_margin={'top': 60, 'bottom': 60, 'left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba66f57ba8840abb4171b8f1df1d375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Previous', disabled=True, style=ButtonStyle()), Button(description='Next', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4920c1e16fe942f88fb23d77adba3a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Shuffle Colors', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interaction_cnn import average_pool\n",
    "average_pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Couche de *Dropout*\n",
    "\n",
    "> La technique du *Dropout* (ou Abandon en français) consiste à couper certaines connections entre neurones de couches consécutives. Cette technique réduit considérablement la quantité de paramètres à entraîner et permet de \"renforcer\" les liens entre neurones consécutifs\n",
    ">\n",
    "> La quantité de connections conservées dépend d'un paramètre **p** qui définit la **proportions de connections à être gardées**. Chaque couche de *dropout* d'un modèle est définie par ce paramètre.\n",
    ">\n",
    "> Dans la figure interactive suivante, nous illustrons deux couches de dropout entre 3 couches denses. La première va garder 4/5 des connections tandis que la deuxième va en garder 2/3.\n",
    "\n",
    "* Pour interagir avec cette figure, cliquer sur le bouton *Next* pour aller à l'étape suivante et *Previous* pour aller à l'étape précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbf91e6c23a42b790f1dd4be8d70033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(animation_duration=1000, background_style={'fill': 'white'}, fig_margin={'top': 60, 'bottom': 60, 'left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3dde9562fb54ba1a9999af4b14a6b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Previous', disabled=True, style=ButtonStyle()), Button(description='Next', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interaction_cnn import show_dropout\n",
    "show_dropout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Merci d'avoir suivi cet exercice introductif sur les différents types de couches utilisées dans le *deep learning*!\n",
    ">\n",
    "> Dans le prochain exercice, nous verrons comment créer et entraîner un réseau convolutionnel sur le problème de classification des chiffres manuscrits avec la package **keras**."
   ]
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Default Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
