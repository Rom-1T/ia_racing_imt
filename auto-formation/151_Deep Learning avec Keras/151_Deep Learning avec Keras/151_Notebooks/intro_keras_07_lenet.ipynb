{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "preliminary",
    "question_id": 1,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" style=\"height:150px\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><h1>Introduction au Deep Learning avec Keras</h1></center>\n",
    "<center><h2>Résolution avec l'architecture LeNet</h2></center>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "\n",
    "## Contexte et objectif\n",
    "\n",
    ">Le principal objectif de l'exercice est de réaliser une reproduction de l'algorithme de Réseau de Neurones Convolutif **LeNet5**  sur Python avec le module Keras. Plus d'infos sur LeNet [ici](http://yann.lecun.com/exdb/lenet/).\n",
    ">\n",
    ">\n",
    ">\n",
    ">L’architecture LeNet a été introduite par Yann LeCun en Novembre 1998 dans le journal [*Proceedings of the IEEE*](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf).\n",
    "> Nous allons reconstruire l'architecture du réseau LeNet qui est plus élaborée que celle créée dans l’exercice précédent. Le réseau LeNet comprend notamment deux couches de convolution, deux couches de *pooling*, ainsi que des layers de *dropout*.\n",
    "\n",
    "* Exécutez la cellule ci-dessous pour importer les modules nécessaires à l'exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "function": "preliminary",
    "question_id": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "preliminary",
    "question_id": 1,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Exécutant la cellule suivante pour charger les données obtenues à l'Exercice 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "function": "preliminary",
    "question_id": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (60000, 784)\n",
      "Shape of y: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Pour importer le datasets mnist de Keras\n",
    "from keras.datasets.mnist import load_data\n",
    "\n",
    "# Chargement des données MNIST\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "# Changer la forme de X_train et X_test\n",
    "X_train = X_train.reshape([-1, 28*28])\n",
    "X_test = X_test.reshape([-1, 28*28])\n",
    "\n",
    "# Shape of X_train and y_train\n",
    "print('Shape of X:', X_train.shape)\n",
    "print('Shape of y:',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "preliminary",
    "question_id": 1,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Transformer les données **X_train** en un tableau à 4 dimensions (nb_images, largeur, hauteur, profondeur). Chacune des images sera ainsi redimensionnée au format (28, 28, 1).\n",
    "\n",
    "\n",
    "* Faire de même pour les données **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "function": "submission",
    "question_id": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution",
    "question_id": 1
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "preliminary",
    "question_id": 2,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Diviser les pixels des données **X_train** et **X_test** par 255 afin qu'ils soient compris entre 0 et 1.\n",
    "\n",
    "\n",
    "* Transformer les labels de **y_train** et **y_test** en vecteurs catégorielles binaires (*one hot*), grâce à la fonction `to_categorical` du sous-module **np_utils** de **keras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "function": "submission",
    "question_id": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution",
    "question_id": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "preliminary",
    "question_id": 3,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> L'architecture du LeNet est constituée des couches suivantes:\n",
    ">> * **Convolution 1** : 30 filtres,  dimension d'entrée (28, 28, 1), dimension du noyau (5, 5), fonction d'activation *ReLU*, pas de dépassement du noyau.\n",
    ">> * **Max-Pooling 1** : dimension du pooling (2, 2).\n",
    ">>\n",
    ">> * **Convolution 2** : 16 filtres, dimension du noyau (3, 3), fonction d'activation *ReLU*, Pas de dépassement du noyau.\n",
    ">> * **Max-Pooling 2** : dimension du pooling (2, 2).\n",
    ">>\n",
    ">> * **Dropout** : Connexions coupées: 20%.\n",
    ">> * **Aplatissement**\n",
    ">> * **Dense 1** : 128 neurones, fonction d'activation *ReLU*.\n",
    ">> * **Dense 2** :  10 neurones, fonction d'activation *softmax*.\n",
    ">\n",
    ">  En image: <img src=\"https://datascientest.fr/train/assets/le_net.png\" style=\"width:auto; height:200px\" />\n",
    "\n",
    "* Instancier l'ensemble de ces couches et les ajouter à un modèle séquentiel.\n",
    "\n",
    "\n",
    "* Compiler le modèle avec la fonction de perte *'categorical_crossentropy'*, l'optimiseur *'adam'* et la métrique *[\"accuracy\"]*.\n",
    "\n",
    "\n",
    "* Entraîner le modèle avec les données d'entraînement sur 16 *epochs* avec des *batchs* de taille 200 et un *split* de validation de 0,2. Stocker la sortie de l'entraînement dans une variable nommée **training_history_lenet**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "submission",
    "question_id": 3
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Lancer la cellule suivante pour extraire de **training_history_lenet** les précisions sur les bases d'entraînement et de validation obtenues pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_acc_lenet = training_history_lenet.history['accuracy']\n",
    "val_acc_lenet = training_history_lenet.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Nous voulons comparer les trois réseaux que nous avons construits jusqu'à maintenant: le réseau dense, le CNN et LeNet.\n",
    "\n",
    "* Lancer la cellule suivante pour instancier, compiler et entraîner les modèles des exercices précédents. L'opération peut prendre quelques minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/16\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 1.2039 - accuracy: 0.7756 - val_loss: 0.5853 - val_accuracy: 0.8827\n",
      "Epoch 2/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.4746 - accuracy: 0.8923 - val_loss: 0.3678 - val_accuracy: 0.9089\n",
      "Epoch 3/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.3480 - accuracy: 0.9109 - val_loss: 0.3005 - val_accuracy: 0.9194\n",
      "Epoch 4/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2947 - accuracy: 0.9207 - val_loss: 0.2683 - val_accuracy: 0.9264\n",
      "Epoch 5/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2629 - accuracy: 0.9281 - val_loss: 0.2475 - val_accuracy: 0.9317\n",
      "Epoch 6/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2404 - accuracy: 0.9336 - val_loss: 0.2327 - val_accuracy: 0.9369\n",
      "Epoch 7/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2234 - accuracy: 0.9377 - val_loss: 0.2225 - val_accuracy: 0.9390\n",
      "Epoch 8/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2100 - accuracy: 0.9414 - val_loss: 0.2130 - val_accuracy: 0.9417\n",
      "Epoch 9/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1992 - accuracy: 0.9437 - val_loss: 0.2058 - val_accuracy: 0.9429\n",
      "Epoch 10/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1899 - accuracy: 0.9463 - val_loss: 0.2020 - val_accuracy: 0.9452\n",
      "Epoch 11/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1818 - accuracy: 0.9484 - val_loss: 0.1972 - val_accuracy: 0.9458\n",
      "Epoch 12/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1745 - accuracy: 0.9508 - val_loss: 0.1939 - val_accuracy: 0.9467\n",
      "Epoch 13/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1686 - accuracy: 0.9520 - val_loss: 0.1910 - val_accuracy: 0.9469\n",
      "Epoch 14/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1628 - accuracy: 0.9533 - val_loss: 0.1916 - val_accuracy: 0.9486\n",
      "Epoch 15/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1580 - accuracy: 0.9550 - val_loss: 0.1871 - val_accuracy: 0.9494\n",
      "Epoch 16/16\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.1538 - accuracy: 0.9551 - val_loss: 0.1858 - val_accuracy: 0.9493\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/16\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.2766 - accuracy: 0.9178 - val_loss: 0.0967 - val_accuracy: 0.9724\n",
      "Epoch 2/16\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.0835 - accuracy: 0.9758 - val_loss: 0.0605 - val_accuracy: 0.9824\n",
      "Epoch 3/16\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0553 - accuracy: 0.9836 - val_loss: 0.0521 - val_accuracy: 0.9845\n",
      "Epoch 4/16\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 0.0496 - val_accuracy: 0.9848\n",
      "Epoch 5/16\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.0522 - val_accuracy: 0.9833\n",
      "Epoch 6/16\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0317 - accuracy: 0.9898 - val_loss: 0.0455 - val_accuracy: 0.9868\n",
      "Epoch 7/16\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.0464 - val_accuracy: 0.9868\n",
      "Epoch 8/16\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0467 - val_accuracy: 0.9867\n",
      "Epoch 9/16\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0504 - val_accuracy: 0.9858\n",
      "Epoch 10/16\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0439 - val_accuracy: 0.9872\n",
      "Epoch 11/16\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0448 - val_accuracy: 0.9877\n",
      "Epoch 12/16\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0428 - val_accuracy: 0.9880\n",
      "Epoch 13/16\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0422 - val_accuracy: 0.9882\n",
      "Epoch 14/16\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0468 - val_accuracy: 0.9878\n",
      "Epoch 15/16\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0473 - val_accuracy: 0.9875\n",
      "Epoch 16/16\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0461 - val_accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "# Réseau Dense\n",
    "\n",
    "dense = Sequential()\n",
    "dense_0 = Flatten()\n",
    "dense_1 = Dense(units = 20, input_dim = 784, kernel_initializer ='normal', activation ='tanh')            \n",
    "dense_2 = Dense(units = 10, kernel_initializer ='normal', activation ='softmax')\n",
    "dense.add(dense_0)\n",
    "dense.add(dense_1)\n",
    "dense.add(dense_2)\n",
    "\n",
    "# CNN\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn_1 = Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', input_shape = (28, 28, 1), activation = 'relu')\n",
    "cnn_2 = MaxPooling2D(pool_size = (2, 2))\n",
    "cnn_3 = Dropout(rate = 0.2)\n",
    "cnn_4 = Flatten()\n",
    "cnn_5 = Dense(units = 128, activation = 'relu')\n",
    "cnn_6 = Dense(units = 10, activation='softmax')\n",
    "\n",
    "cnn.add(cnn_1)\n",
    "cnn.add(cnn_2)\n",
    "cnn.add(cnn_3)\n",
    "cnn.add(cnn_4)\n",
    "cnn.add(cnn_5)\n",
    "cnn.add(cnn_6)\n",
    "\n",
    "# Compilation\n",
    "dense.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])           \n",
    "cnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])            \n",
    "\n",
    "# Entraînement\n",
    "training_history_dense = dense.fit(X_train, y_train, validation_split = 0.2, epochs = 16, batch_size = 200, verbose = 1)\n",
    "training_history_cnn = cnn.fit(X_train, y_train, validation_split = 0.2, epochs = 16, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Nous avons stocké la sortie de leurs entraînements dans les variables **training_history_dense** et **training_history_cnn**.\n",
    "\n",
    "* Extraire de ces deux dictionnaires les précisions sur la base de validation obtenues pendant l'entraînement de chacun des modèles.\n",
    "\n",
    "\n",
    "* À l'aide du module *matplotlib.pyplot*, tracer les évolutions des précisions sur la base de validation des trois modèles. On rapelle que l'entraînement s'est fait sur *16 epochs* pour les trois modèles.\n",
    "\n",
    "\n",
    "* Quel modèle vous paraît être le plus performant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "preliminary",
    "question_id": 8,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Prédire les classes de l'échantillon **X_test** à l'aide de la méthode `predict` du modèle LeNet. Stocker le résultat dans un tableau nommé **test_pred_lenet**.\n",
    "\n",
    "\n",
    "* Faire de même pour les deux autres modèles et stocker le résultat dans **test_pred_dense** et **test_pred_cnn**.\n",
    "\n",
    "\n",
    "* Appliquer la méthode `argmax` sur les tableaux **test_pred_lenet**, **test_pred_dense**, **test_pred_cnn** et **y_test** pour obtenir des vecteurs d'entiers correspondant aux classes prédites et réelles. Il faudra passer l'argument '`axis = 1`' pour que l'argmax soit calculée sur les colonnes et non les lignes. Stocker les sorties des appels de la méthode `argmax` dans des tableaux nommés **test_pred_lenet_class**, **test_pred_dense_class**, **test_pred_cnn_class** et **y_test_class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Afficher un compte-rendu évaluatif détaillé de la perfomance du modèle **lenet** à l'aide de la fonction `classification_report` du sous-module **metrics** de **scikit-learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Lancer la cellule suivante pour voir les images de la base de test où les trois modèles se sont trompés. Vous pouvez la relancer plusieurs fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_indexes = []\n",
    "for i in range(len(test_pred_cnn)):\n",
    "    if (test_pred_lenet_class[i] != y_test_class[i]):\n",
    "        if(test_pred_dense_class[i] != y_test_class[i]):\n",
    "            if(test_pred_cnn_class[i] != y_test_class[i]):\n",
    "                error_indexes += [i]\n",
    "\n",
    "j = 1\n",
    "for i in np.random.choice(error_indexes, size = 3):\n",
    "    img = X_test[i] \n",
    "    img = img.reshape(28, 28)\n",
    "    \n",
    "    plt.subplot(1, 3, j)\n",
    "    j = j + 1\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap = cm.binary, interpolation='None')\n",
    "    plt.title('True Label: ' + str(y_test_class[i]) \\\n",
    "              + '\\n' + 'Prediction: '+ str(test_pred_lenet_class[i]) \\\n",
    "              + '\\n' + 'Confidence: '+ str(round(test_pred_lenet[i][test_pred_lenet_class[i]], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "preliminary",
    "question_id": 11,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> On remarque que certains des chiffres mal identifiés sont parfois très mal écrits, certains ne sont même pas reconnaissables.\n",
    ">\n",
    "> Avec un taux de précision dépassant les 99% pour quelques minutes d'entraînement, on peut affirmer qu'au moins un des trois modèles a rempli son objectif.\n",
    "\n",
    "### Ce qu'il faut retenir : \n",
    "\n",
    "\n",
    "> Les réseaux de neurones construits séquentiellement sont des outils de machine learning désormais accessibles offrant des résultats pouvant surpasser de loin les algorithmes classiques sur des tâches non-triviales.\n",
    ">\n",
    ">Le schéma pour implémenter un modèle avec keras est très simple:\n",
    "> * Architecture du modèle\n",
    "> * Compilation du modèle\n",
    "> * Entraînement du modèle\n",
    "> * Diagnostique de l'entraînement\n",
    "> * Evaluation des prédictions"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Default Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "n_questions": 11
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
