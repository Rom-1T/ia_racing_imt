{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" style=\"height:150px\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h1 style = \"text-align:center\" > Introduction à TensorFlow </h1>\n",
    "<h2 style = \"text-align:center\" > Transfer Learning </h2>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "> Bienvenue dans le dernier exercice du module d'introduction à Tensorflow. Cet exercice a pour objectif de vous rappeler le fonctionnement du **transfer learning** et traiter toutes les étapes d'un problème de classification d'image.\n",
    ">\n",
    "> Le jeu de données est constitué d'image de radiographie contenant quatre classes : **glioma tumor**, **meningioma tumor**, **no tumor**, **pituitary tumor**. Vous trouverez plus d'informations sur le jeu de données [ici](https://www.kaggle.com/sartajbhuvaji/brain-tumor-classification-mri).\n",
    ">\n",
    "><img src='https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/introduction_tensorflow_tumors.png'>\n",
    ">\n",
    ">Les images se trouvent dans le dossier `Training` et `Testing`. Et, une fois dans le dossier, les images de chaque classe se trouvent dans des dossiers séparés.\n",
    ">\n",
    "><img src='https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/introduction_tensorflow_folder_image.png'>\n",
    "\n",
    "* Exécuter la cellule suivant permettant de créer un dataframe **`df`** contenant le chemin vers l'image et la classe correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>nameLabel</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Training/meningioma_tumor/m3 (67).jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Training/meningioma_tumor/m1(122).jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Training/meningioma_tumor/m2 (81).jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Training/meningioma_tumor/m3 (77).jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Training/meningioma_tumor/m (192).jpg</td>\n",
       "      <td>meningioma_tumor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filepath         nameLabel  label\n",
       "0  ./Training/meningioma_tumor/m3 (67).jpg  meningioma_tumor      0\n",
       "1  ./Training/meningioma_tumor/m1(122).jpg  meningioma_tumor      0\n",
       "2  ./Training/meningioma_tumor/m2 (81).jpg  meningioma_tumor      0\n",
       "3  ./Training/meningioma_tumor/m3 (77).jpg  meningioma_tumor      0\n",
       "4  ./Training/meningioma_tumor/m (192).jpg  meningioma_tumor      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "# Trouver tous les chemins vers les fichiers qui finissent par .jpg\n",
    "liste = glob.glob('./Training/*/*.jpg')\n",
    "# Extraire le label de chaque image\n",
    "liste = list(map(lambda x : [x, x.split('/')[2]], liste))\n",
    "# Créer un dataframe pandas\n",
    "df = pd.DataFrame(liste, columns=['filepath', 'nameLabel'])\n",
    "df['label'] = df['nameLabel'].replace(df.nameLabel.unique(), [*range(len(df.nameLabel.unique()))])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Exploration des données\n",
    "\n",
    "> Maintenant que la correspondance entre chemin et classe est faite, intéressons-nous maintenant aux images.\n",
    ">\n",
    "> La fonction `read_file` de **`tensorflow.io`** permet de charger l'information brute d'un fichier (image, fichier audio, dossier texte ...). Ensuite, la fonction `decode_jpeg` de **`tensorflow.image`** permet de décoder l'information brute en un tensor de type `uint8` ou `uint16` :\n",
    ">\n",
    "> ```python\n",
    "># Charger l'information brute en mémoire\n",
    ">im = tf.io.read_file(filepath)\n",
    "># Decoder l'information en un tensorflow RGB (3 channels).\n",
    ">im = tf.image.decode_jpeg(im, channels=3)\n",
    ">\n",
    ">```\n",
    ">\n",
    "> <div class=\"alert alert-info\">\n",
    "<i class=\"fa fa-info-circle\"></i> &emsp; \n",
    "On peut utiliser le package `matplotlib` ou `OpenCV` pour charger les images, mais, les fonctions de tensorflow sont plus performantes quand ils sont utilisés dans l'architecture du modèle.\n",
    "</div>\n",
    "\n",
    "* Charger une des images de notre dataframe.\n",
    "\n",
    "\n",
    "* Afficher l'image à l'aide de la fonction `imshow` de **`matplotlib.pyplot`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Les modèles en Deep learning n'accepte en générale que des entrées de même dimension, il est alors nécessaire de redimensionner toutes les images pour qu'elles aient la même taille. D'après la littérature, la dimension optimale entre perte d'information et complexité est aux alentours  de (256,256).\n",
    ">\n",
    "> La fonction `resize` de **`tensorfow`** permet de redimensionner une image en dimension `size`:\n",
    ">\n",
    ">```python\n",
    "># Redimensionner l'image en (256,256)\n",
    ">im = tf.image.resize(im, size=(256,256))\n",
    ">```\n",
    "\n",
    "* Redimensionner l'image chargée précédemment en (256,256)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Charger le jeu de données\n",
    "\n",
    "> Le modèle a besoin pour s'entraîner d'images/labels. Ces images peuvent soit être tous chargées initialement ou soit être chargées quand le modèle en a besoin. Il arrive que le jeu de données soit constitué de centaines de millier d'images, dans ce cas, il n'est pas concevable de les charger au préalable en mémoire (nécessite de 40Go de RAM pour 150k images 256x256x3).\n",
    ">\n",
    "> Dans ce cas, deux solutions sont disponibles :\n",
    ">\n",
    ">>* Comme le jeu de données est trop lourd, choisir un sous-échantillon (ex : 30 000 images) et le charger en mémoire.\n",
    ">>\n",
    ">>\n",
    ">>* Charger les images pendant l'entraînement à l'aide d'un générateur. Solution à privilégier si le pré-processing n'est pas trop lourd.\n",
    ">\n",
    "> Les deux solutions fonctionnent, dans cet exercice nous allons **choisir la deuxième**. Comme le jeu de test est généralement plus petit, il peut être chargé en mémoire.\n",
    ">\n",
    "> <div class=\"alert alert-info\">\n",
    "<i class=\"fa fa-info-circle\"></i> &emsp; \n",
    "La structure des données nous permettrait d'utiliser les instances `ImageDataGenerator` de <b>tensorflow.keras.preprocessing.image</b> pour charger les données quand le modèle en a besoin. Mais, cette instance reste très limitée, convient généralement que pour des problèmes de classification.\n",
    "</div>\n",
    "\n",
    "* Séparer le jeu de données **`df.filepath`** et la variable cible **`df.label`** en un ensemble d'entraînement **X_train_path**, **y_train**, et en un ensemble de test **X_test_path**, **y_test**. Nous choisirons un rapport de 80% pour les données d'entraînements et une graine aléatoire 1234.\n",
    "\n",
    "\n",
    "* Charger les images de **X_test_path** redimensionnées à [256,256,3]  en mémoire dans la variable **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [00:01<00:00, 362.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_path, X_test_path, y_train, y_test = train_test_split(df.filepath, df.label, test_size = 0.2, random_state = 1234)\n",
    "\n",
    "X_test = []\n",
    "for filepath in tqdm(X_test_path):\n",
    "    # Read the file\n",
    "    im = tf.io.read_file(filepath)\n",
    "    # Decode the file\n",
    "    im = tf.image.decode_jpeg(im, channels=3)\n",
    "    # Resizing\n",
    "    im = tf.image.resize(im, size=(256,256))\n",
    "    X_test.append([im])\n",
    "    \n",
    "X_test = tf.concat(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Maintenant les données de test chargées, il est nécessaire de définir un **dataset** permettant charger les images à chaque itération du modèle. Pour optimiser le temps de chargement/pré-traitement, il est possible de paralléliser chaque opération en utilisant une structure multi-tasking.\n",
    ">\n",
    "> Les objet de type **dataset** sur tensorflow sont capables de le faire à l'aide de l'argument **num_parallel_calls** de la méthode `map`.\n",
    ">\n",
    "> Pour rappel, le constructeur `from_tensor_slices` du package **tensorflow.data.Dataset** permet de convertir une liste d'array en un dataset.\n",
    ">\n",
    "> ```python\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_path, y))\n",
    "> ```\n",
    "> La méthode `map` du dataset permet d'appliquer une opération à chaque observation. Exemple :\n",
    ">\n",
    "> ```python\n",
    "dataset = dataset.map(lambda x, y : [load_image(x), y])\n",
    "> ```\n",
    ">\n",
    "> La méthode `batch` du dataset permet de regrouper les observations sous forme de batch.\n",
    ">\n",
    "><img src=\"https://datascientest.fr/train/assets/tensorflow_02_batch.png\" style=\"width:400px\">\n",
    ">\n",
    "> ```python\n",
    "dataset = dataset.batch(batch_size)\n",
    "> ```\n",
    "\n",
    "* Définir une fonction `load_image` avec comme argument `filepath` retournant une image redimensionnée en (256,256).\n",
    "\n",
    "\n",
    "* Définir un dataset **`dataset_train`** de **`(X_train_path, y_train)`** à l'aide de la fonction `from_tensor_slices`.\n",
    "\n",
    "\n",
    "* À l'aide de la méthode `map`, appliquer la fonction `load_image` à chaque valeur de **X_train_path**. Pour que le chargement s'effectue en multi-tasking, préciser l'argument `num_parallel_calls` égale à -1.\n",
    "\n",
    "\n",
    "* Regrouper les observations sous forme de batch de taille 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Les modèles de classification d'image ou de détection d'objet utilise généralement une approche par transfer Learning.\n",
    "\n",
    "### Quelques rappels sur le transfer leaning :\n",
    "\n",
    "> L'apprentissage par transfert est le phénomène par lequel un apprentissage nouveau est facilité grâce aux apprentissages antérieurs partageant des similitudes. Par exemple, les connaissances acquises lors de l’apprentissage de la reconnaissance des voitures peuvent s’appliquer lorsqu’on essaie de reconnaître des camions.\n",
    ">\n",
    "> Les modèles existants (VGG, ResNet, ...) sont composés de deux grandes parties. La première appelée **backbone** est un ensemble de convolution permettant l'**extraction des features de l'image**. La seconde est une succession de dense layer qui a pour but de classifier.\n",
    ">\n",
    "> Les données du nouveau problème doit être assez semblable avec le jeu de données utilisé pour le pré-entrainement. Dans ce cas, la méthode de transfer learning consiste à utiliser le **backbone** d'un modèle pré-entraîné comme extraction de features. Ensuite des couches `Dense` sont ajouté pour traiter le problème de classification ou de regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e383e5adbdd49d2b43acf145fd708d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00`\\x00`\\x00\\x00\\xff\\xdb\\x00C\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87c2cbf7f174a64a9f93cddda0db49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Previous', disabled=True, icon='backward', layout=Layout(height='30%', widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from interaction_tl import show_tl\n",
    "show_tl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Lors du début de l'apprentissage, il est nécessaire de \"freezer\" (bloquer) les poids de la partie pré-entrainée (**backbone**) puisqu'ils sont proches des poids optimaux. Puis, au courant de l'entraînement, on peut \"unfreeze\" les couches pour affiner les poids du modèle : cet opération est appelée le **fine-tuning**.\n",
    ">\n",
    "> <img src=\"https://datascientest.fr/train/assets/python_keras_picasso_unfreeze1.png\" style=\"width:800px\">\n",
    ">\n",
    "> Dans cet exercice, le modèle pré-entraîné sera le EfficientNet puisqu'il a montré de très bon résultat et de très bonne propriété pour le transfer learning.\n",
    ">\n",
    "> Voici un exemple pour charger et freeze les poids d'une modèle pré-entraîné :\n",
    ">\n",
    "> ```python\n",
    "vgg16 = VGG16(include_top=False, input_shape=(256,256,3))\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential()\n",
    "model.add(vgg16)\n",
    ">```\n",
    "\n",
    "* Charger le modèle `EfficientNetB1` de **`tensorflow.keras.applications`** sous le nom **`efficientNet`**. La partie classification ne sera pas prise et l'`input_shape` sera (256,256,3).\n",
    "\n",
    "\n",
    "* Freezer les poids du modèle.\n",
    "\n",
    "\n",
    "* Afficher le résumé du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Partie Classification\n",
    "\n",
    "* Ajouter le modèle pré-entraîné à un objet `Sequential` qui portera le nom de **model**.\n",
    "\n",
    "\n",
    "* Ajouter à ce modèle une couche `GlobalAveragePooling2D`.\n",
    "\n",
    "\n",
    "* Puis, ajouter quelques couches `Dense` et `Dropout`.\n",
    "\n",
    "\n",
    "* Finir par une couche `Dense` avec 4 neurones et une fonction activation 'softmax'.\n",
    "\n",
    "\n",
    "* Afficher le résumé du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Compiler le modèle avec votre fonction de perte `sparse_categorical_crossentropy`, un optimizer `'adam'` et une métrique `['accuracy']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Entraînement du modèle\n",
    "\n",
    "\n",
    "* Entraîner le modèle à l'aide la méthode `fit` sur 10 epochs en ajoutant les callbacks suivants :\n",
    "    * Ajouter une sauvegarde des poids à chaque epoch à l'aide du callbacks `ModelCheckpoint`.\n",
    "    \n",
    "    * Diminuer le learning rate si la métrique de validation ne s'améliore pas dans les 5 dernières époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "$\\DeclareMathOperator*{\\argmax}{argmax}$\n",
    "\n",
    "## Évaluation\n",
    "\n",
    "> La fonction d'activation **softmax** utilisée à la fin de notre modèle, fait que celui-ci retourne pour chaque image une probabilité de prédiction de chaque classe.\n",
    ">\n",
    "> $$ \\mathbf{P(\\ y\\ |\\ X\\ )} =\n",
    "\\begin{bmatrix}\n",
    "    P(y=0|X)  \\\\\n",
    "    P(y=1|X)  \\\\\n",
    "    \\vdots  \\\\\n",
    "    P(y=9|X) \n",
    "\\end{bmatrix}$$\n",
    ">\n",
    "> Pour prédire la classe de l'image, il suffit alors de trouver pour quelle classe la probabilité est maximale :\n",
    ">\n",
    "> $$ \\hat{y} = \\argmax_{y}(P(\\ y\\ |\\ X\\ ) $$ \n",
    "\n",
    "* Prédire la probabilité des classes du jeu de données **X_test**.\n",
    "\n",
    "\n",
    "* Prédire dans **y_pred** la classe la plus probable à l'aide de la fonction `argmax` de **`tensorflow`** en précisant `axis=-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Afficher le score de précision à l'aide de la fonction `accuracy_score` de **`sklearn.metrics`**.\n",
    "\n",
    "\n",
    "* Afficher la matrice de confusion à l'aide de la fonction `confusion_matrix` de **`sklearn.metrics`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Exécuter la cellule suivante pour afficher les prédictions de notre modèle sur 3 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h2 style = \"text-align:center\" > Ce qu'il faut retenir de ce module </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "## Méthodologie\n",
    "\n",
    "> Globalement, la méthodologie pour résoudre un problème à l'aide d'outil de deep learning :\n",
    ">\n",
    ">1. Définir un **dataset** permettant de mettre en forme les données et de partitionner en batchs.\n",
    ">\n",
    ">\n",
    ">2. Construire un modèle : MLP, CNN, RNN, transfer learning ...\n",
    ">\n",
    ">\n",
    ">3. Compiler le modèle : définition d'une fonction de perte, métrique, optimizer.\n",
    ">\n",
    ">\n",
    ">4. Entraîner le modèle, il y'a deux manières équivalentes de le faire:\n",
    ">    - Méthode **`fit`**: problème simple.\n",
    ">    - Calculer le gradient de la fonction de coût puis rétropropager l'erreur: problème complexe.\n",
    ">    \n",
    ">    \n",
    ">5. Prédiction et évaluation du modèle.\n",
    "\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "> Tensorflow possède un sous ensemble **`tensorflow.data.dataset`**  qui permet d'appliquer toutes les étapes de pré-processing sur les données. C'est un pipeline d'opération appliqué sur les entrées. Un exemple :\n",
    ">\n",
    "> * Charger les images + redimensionner (en paralélisant les calculs).\n",
    ">\n",
    ">\n",
    "> * Appliquer des méthodes d'augmentation de données.\n",
    ">\n",
    ">\n",
    "> * Normaliser nos données.\n",
    ">\n",
    ">\n",
    "> * Les regrouper en lot de données.\n",
    "\n",
    "\n",
    "\n",
    "## Keras\n",
    "\n",
    "> La version de tensorflow 2.0+ a été construite autour du framework [**keras**](https://www.tensorflow.org/guide/keras).\n",
    ">\n",
    "> Vous pouvez retrouver toutes les fonctionnalités de **keras** dans **`tensorflow.keras`**. Il y'a notamment :\n",
    ">\n",
    ">* Les couches de neurones dans **`tensorflow.keras.layers`**. Il est possible de créer des couches personnalisées en faisant hériter la classe de la couche avec **`tensorflow.keras.layers.Layer`**.\n",
    ">\n",
    ">\n",
    ">* Les modèles pré-entrainés dans  **`tensorflow.keras.applications`**.\n",
    ">\n",
    ">\n",
    ">* Les fonctions de pertes dans **`tensorflow.keras.losses`**\n",
    ">\n",
    ">\n",
    ">* Les métriques dans **`tensorflow.keras.metrics`**.\n",
    ">\n",
    ">\n",
    ">* Les optimizers dans **`tensorflow.keras.optimizers`**.\n",
    "\n",
    "## Callbacks\n",
    "\n",
    "\n",
    "> Les rappels (***callbacks***) sont des outils qui permettent de contrôler l'entraînement et évaluation d'un modèle. Il est alors possible de connaître l'état interne d'un modèle, de le sauvegarder, d'afficher des statistiques intéressantes et même de changer des hyperparamètres pendant les étapes de l'entraînement.\n",
    ">\n",
    "> Les callbacks suivants peuvent être très pratique en Deep Learning :\n",
    ">\n",
    "> * Sauvegarder les meilleurs poids du modèle au cours de l'entraînement :\n",
    ">\n",
    ">```python\n",
    ">callbacks.ModelCheckpoint(filepath = filepath, \n",
    ">                           monitor = 'val_loss',\n",
    ">                           save_best_only = True,\n",
    ">                           save_weights_only = False,\n",
    ">                           mode = 'min',\n",
    ">                           save_freq = 'epoch')\n",
    ">\n",
    ">```\n",
    ">\n",
    "> * Réduire automatiquement le learning rate :\n",
    ">\n",
    ">```python\n",
    ">callbacks.ReduceLROnPlateau(monitor = 'val_loss',\n",
    ">                             patience=5,\n",
    ">                             factor=0.5,\n",
    ">                             verbose=2,\n",
    ">                             mode='min')\n",
    ">```\n",
    ">\n",
    "> * Arrêter l'entraînement si le modèle n'évolut plus. Très pratique pour ne pas gérer le nombre d'époque et laisser le modèle s'arrêter quand il n'évolut plus.\n",
    ">\n",
    ">```python\n",
    ">callbacks.EarlyStopping(monitor = 'val_loss',\n",
    ">                         patience = 8,\n",
    ">                         mode = 'min',\n",
    ">                         restore_best_weights = True)\n",
    ">```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9aec066b96c3e0d9844eb4d79219d346f0541a322afe8db83adf42c69178cf43"
  },
  "kernelspec": {
   "display_name": "Deep env test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
