{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" style=\"height:150px\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h1 style = \"text-align:center\" > Introduction à TensorFlow </h1>\n",
    "<h2 style = \"text-align:center\" > Couches et modèles personnalisés </h2>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "> Les deux précédents exercices ont présenté quelques couches standards très utile en Deep learning (`Dense`, `Conv2D`...). Quelques fonctions de perte ou métriques prédéfinies ont été également utilisées.\n",
    ">\n",
    "> Il s'agit maintenant de personnaliser le tout: de la création de couches et de modèles, la définition des loss et métriques, jusqu'à l'entrainement et la prédiction.\n",
    "\n",
    "\n",
    "## Couche personnalisée : Classe Layer\n",
    "\n",
    "\n",
    "> La meilleure façon de créer ses propres couches personnalisées est de faire hériter la classe `Layer`. La classe devra également avoir au moins les 3 méthodes suivantes :\n",
    ">\n",
    "> * `__init__`: Initialise la classe `Layer` et définit les hyperparamètres de la couche.\n",
    ">\n",
    ">\n",
    "> * `build` : Initialise les poids de la couche.\n",
    ">\n",
    ">\n",
    "> * `call` : Applique l'opération sur l'entrée.\n",
    ">\n",
    ">\n",
    "> Exemple pour la regression linéaire :\n",
    ">\n",
    ">```python\n",
    ">from tensorflow.keras.layers import Layer\n",
    ">\n",
    ">class CustomLinear(Layer):\n",
    ">     def __init__(self, units):\n",
    ">         super(CustomLinear, self).__init__()\n",
    ">         self.units = units\n",
    ">\n",
    ">     def build(self, input_shape):\n",
    ">         self.w = self.add_weight(\n",
    ">            shape = (input_shape[-1], self.units),\n",
    ">            initializer = \"random_normal\",\n",
    ">            trainable = True\n",
    ">         )\n",
    ">         self.b = self.add_weight(\n",
    ">            shape = (self.units,), \n",
    ">            initializer = \"random_normal\",\n",
    ">            trainable = True\n",
    ">         )\n",
    ">\n",
    ">     def call(self, inputs):\n",
    ">         return tf.matmul(inputs, self.w) + self.b\n",
    ">```\n",
    ">\n",
    "> Une fois la couche définie, l'appel de l'instance va automatiquement initialiser les poids de la couche :\n",
    ">\n",
    ">```python\n",
    "> # Définition d'une couche CustomLinear\n",
    ">linear = CustomLinear()\n",
    "> # Initialisation des poids ainsi que transforme l'entrée data\n",
    ">linear(data)\n",
    ">```\n",
    ">\n",
    "> Nous allons maintenant créer une couche représentant une régression polynomiale d'ordre 2 contenant des poids `w` et un biais `b`, cette couche va transformer les entrées en leur appliquant une combinaison linéaire avec les poids.\n",
    "\n",
    " \n",
    "* Importer le module `tensorflow` sous le nom `tf`\n",
    "\n",
    "\n",
    "* Importer la classe `Layer` de `tensorflow.keras.layers`\n",
    "\n",
    " \n",
    "* Créer une classe **`CustomPolynomial`** qui hérite de la classe `Layer`. \n",
    "     * Dans le constructeur de cette classe `__init__` avec comme argument `self`, `units` :\n",
    "         * Initialiser les objets de la classe de base `Layer`.\n",
    "         * Ajouter l'attribut `units` à la classe.\n",
    "     \n",
    "     * Dans la méthode `build`, initialiser deux attributs $w$ et $b$ à l'aide de la méthode `add_weight`. Attention à bien multiplier la shape de w par deux (regression polynomiale d'ordre 2).\n",
    "     \n",
    "     * Dans l'appel `call` de la classe, concaténer l'entrée **inputs** avec **inputs^2**, puis appliquer une combinaison linéaire de ce résultat avec les poids `w` et qui rajoute un biais `b`.\n",
    "     ```python\n",
    "     def call(self, inputs):\n",
    "         # inputs**2\n",
    "         inputs_pow = tf.pow(inputs, 2)\n",
    "         # Concatenation inputs and inputs**2\n",
    "         inputs_process = tf.concat([inputs, inputs_pow], axis=-1)\n",
    "         # Combinaison linéaire entre inputs_process et w\n",
    "         return tf.matmul(inputs_process, self.w) + self.b\n",
    "     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Instancier un objet **`customlayer`** de la classe `CustomPolynomial` à 8 unités \n",
    "\n",
    "\n",
    "* Créer un tenseur **`inputs`** de dimensions (4,5) contenant que des 1.\n",
    "\n",
    "\n",
    "* Appliquer la transformation de la couche `customlayer` à inputs.\n",
    "\n",
    "\n",
    "* Afficher le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> La classe `Layer` permet de stocker les poids de chaque couche dans les <b>attributs</b> `weights`, `trainable_weights` et `non_trainable_weights` :\n",
    ">\n",
    "> * `weights` : L'ensemble des poids de la couche.\n",
    ">\n",
    ">\n",
    "> * `trainable_weights` : Seulement les poids entrainables\n",
    ">\n",
    ">\n",
    "> * `non_trainable_weights` : Seulement les poids non entrainables \n",
    "\n",
    "* Afficher le nombre de poids :\n",
    "    * de la couche `customlayer`.\n",
    "    \n",
    "    * entrainable de la couche `customlayer`.\n",
    "    \n",
    "    * non entrainable de la couche `customlayer` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of weights:  2\n",
      "number of trainable weights:  2\n",
      "number of non trainable weights 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> L'un des paramètres importants de la classe `Layer` est **`training`**, il permet de différencier le comportement du modèle en cas d'entraînement ou d'inférence (prédiction). Cette notion est notamment important dans les couches de `Dropout` et de `BatchNormalization`. \n",
    "\n",
    "\n",
    "* Créer une couche personnalisée `CustomDropout` qui initialise un attribut `rate`.\n",
    "\n",
    "\n",
    "* Dans l'appel `call` de la classe avec comme argument `inputs` et `training = None` :\n",
    "    * S'il y a <b>entrainement</b>, retourne un dropout des entrées à l'aide de la fonction `dropout` de `tf.nn` (en paramètre les entrées et le taux `rate`).\n",
    "\n",
    "    * S'il n'y a <b>pas d'entrainement</b>, retourne les entrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## La classe Model\n",
    "\n",
    "> Grace à la classe `Layer`, il est très facile de créer des couches personnalisées compatibles avec le constructeur `Sequential`. Il est également possible de créer, de la même façon, un modèle personnalisé en faisant hériter cette fois la classe `Model`.\n",
    ">\n",
    "> L'initialisation du modèle permet de définir toutes les couches nécessaires en attributs. L'appel du modèle, quant à lui, permet de passer nos entrées à travers les différentes couches du modèle :\n",
    ">\n",
    "> ```python\n",
    ">from tensorflow.keras.models import Model\n",
    ">from tensorflow.keras.layers import Softmax\n",
    ">\n",
    ">class CustomModel(Model):\n",
    ">     def __init__(self, units_1, units_2, n_classes):\n",
    ">         # Initialisation de la classe Model.\n",
    ">         super(CustomModel, self).__init__()\n",
    ">         # Définition de chaque couche de notre modèle.\n",
    ">         self.linear_1 = CustomLinear(units_1)\n",
    ">         self.dropout_1 = CustomDropout(rate=0.2)\n",
    ">        \n",
    ">         self.linear_2 = CustomLinear(units_2)\n",
    ">         self.dropout_2 = CustomDropout(rate=0.2)\n",
    ">        \n",
    ">         self.linear_3 = CustomLinear(n_classes)\n",
    ">         self.softmax = Softmax()\n",
    ">\n",
    ">     def call(self, inputs):\n",
    ">         # Appliquer l'opération de chaque couche.\n",
    ">         x = self.linear_1(inputs)\n",
    ">         x = tf.nn.relu(x)\n",
    ">         x = self.dropout_1(x)\n",
    ">        \n",
    ">         x = self.linear_2(x)\n",
    ">         x = tf.nn.relu(x)\n",
    ">         x = self.dropout_2(x)\n",
    ">        \n",
    ">         x = self.linear_3(x)\n",
    ">         return self.softmax(x)\n",
    ">\n",
    ">```\n",
    ">\n",
    "> L'avantage d'utiliser la classe **`Model`** par rapport à la classe **`Layer`** :\n",
    ">\n",
    ">\n",
    ">>* Possède les méthodes suivantes : `fit`, `evaluate`, `predict`.\n",
    ">>\n",
    ">>\n",
    ">>* Contient ses propres couches internes, accessibles à l'aide de `model.layers`.\n",
    ">>\n",
    ">>\n",
    ">>* Permet de sauvegarder et sérialiser : `save_weights`, `load_weights`.\n",
    "\n",
    "Ici, nous pouvons nous contenter du constructeur `Sequential` :\n",
    "\n",
    "* Définir un modèle par couche vierge **model** à l'aide du constructeur `Sequential`.\n",
    "\n",
    "\n",
    "* Ajouter une couche `CustomPolynomial` avec 32 units.\n",
    "\n",
    "\n",
    "* Ajouter une couche `CustomDropout` avec 0.2 comme rate.\n",
    "\n",
    "\n",
    "* Ajouter une couche d'activation `ReLU` de `tensorflow.keras.layers`.\n",
    "\n",
    "\n",
    "* Ajouter une couche `CustomPolynomial` avec 64 units.\n",
    "\n",
    "\n",
    "* Ajouter une couche `CustomDropout` avec 0.2 comme rate.\n",
    "\n",
    "\n",
    "* Ajouter une couche d'activation `ReLU` de `tensorflow.keras.layers`.\n",
    "\n",
    "\n",
    "* Ajouter une couche `CustomPolynomial` avec 1 unit.\n",
    "\n",
    "\n",
    "* Ajouter une couche d'activation `ReLU` de `tensorflow.keras.layers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Afficher le résultat que retourne le modèle pour un vecteur de 1 de taille [10,5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> Nous allons maintenant traiter un problème de régresion avec notre modèle personnalisé fraichement créé.\n",
    "\n",
    "* Charger le jeu de données <i>\"airfoil_data.csv\"</i> dans le dataframe **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('airfoil_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Séparer les données en **`features`** et **`target`** sachant que la variable cible est \"PressureLevel\".\n",
    "\n",
    "\n",
    "* Séparer les données en un ensemble d'entrainement (**X_train**, **y_train**) et en un ensemble de test (**X_test**, **y_test**). On peut prendre une proportion de 20% pour l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Exécuter la cellule suivante pour normaliser nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "y_train = y_train.ravel().reshape(-1, 1)\n",
    "y_test = y_test.ravel().reshape(-1, 1)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# Features\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "# Target\n",
    "y_train = y_scaler.transform(y_train)\n",
    "y_test = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Compiler notre modèle **model** avec un optimizer `Adam`, une fonction de perte `MeanSquaredError` et une métrique `MeanAbsoluteError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* Entraîner le modèle sur `X_train` et `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "function": "solution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h2 style = \"text-align:center\" > Ce qu'il faut retenir </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "> Il est ainsi possible de créer des couches et des modèles personnalisés tout en profitant de l'API de keras qui fournit des méthodes utiles à la modélisation et l'entrainement.\n",
    ">\n",
    "> Beaucoup de modèle nécessite d'utilise des couches personnalisées ou une structure bien particulière. C'est notamment le cas pour les modèles célèbres suivants:\n",
    ">\n",
    "> * Seq2seq : modèle sequence-to-sequence\n",
    ">\n",
    ">\n",
    "> * Transformer : modèle de BERT, modèle CamemBERT, XLNet ...\n",
    ">\n",
    ">\n",
    "> * WaveNet : modèle basé sur des convolutions 1D.\n",
    ">\n",
    ">\n",
    "> * Spatial Transformer Networks : Remplacer la couche de pooling (https://kevinzakka.github.io/2017/01/18/stn-part2/)\n",
    ">\n",
    ">\n",
    "> Il est aussi possible d'accéder à d'avantages de couches/modèles prédéfinies sur [TensorFlow Hub](https://www.tensorflow.org/hub?hl=fr)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9aec066b96c3e0d9844eb4d79219d346f0541a322afe8db83adf42c69178cf43"
  },
  "kernelspec": {
   "display_name": "Deep env test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
